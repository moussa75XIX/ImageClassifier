{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_wqSAZExy6xV"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import ctypes\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ------------------------------------------- ####\n",
    "#### ------------- LOAD THE DATA --------------- ####\n",
    "#### ------------------------------------------- ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DATASET_FOLDER = \"..\\\\dataset\\\\\"\n",
    "\n",
    "TEST_SUBFOLDER = os.path.join(MAIN_DATASET_FOLDER, \"test\")\n",
    "TRAIN_SUBFOLDER = os.path.join(MAIN_DATASET_FOLDER, \"train\")\n",
    "\n",
    "TEST_ESPAGNE_FOLDER = os.path.join(TEST_SUBFOLDER, \"espagne\")\n",
    "TEST_FRANCE_FOLDER = os.path.join(TEST_SUBFOLDER, \"france\")\n",
    "TEST_JAPON_FOLDER = os.path.join(TEST_SUBFOLDER, \"japon\")\n",
    "\n",
    "TRAIN_ESPAGNE_FOLDER = os.path.join(TRAIN_SUBFOLDER, \"espagne\")\n",
    "TRAIN_FRANCE_FOLDER = os.path.join(TRAIN_SUBFOLDER, \"france\")\n",
    "TRAIN_JAPON_FOLDER = os.path.join(TRAIN_SUBFOLDER, \"japon\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_x_and_y_with_images_and_labels(folder, classe, dataset):\n",
    "\n",
    "    for file in os.listdir(folder):\n",
    "\n",
    "        file_path = os.path.join(folder, file)\n",
    "        image = Image.open(file_path)\n",
    "        image = image.resize((64, 64))\n",
    "        if image.mode in (\"RGB\", \"P\"): image = image.convert(\"RGBA\")\n",
    "        im_arr = np.array(image).flatten()\n",
    "        im_arr = im_arr / 255.0\n",
    "\n",
    "        completed_dataset = {}\n",
    "        completed_dataset[\"value\"] = im_arr\n",
    "        completed_dataset[\"classe\"] = classe\n",
    "\n",
    "        dataset.append(completed_dataset.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataset(folder, classe):\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    fill_x_and_y_with_images_and_labels(folder, classe, dataset)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "class_espagne_expected_outputs = [1, 0, 0]\n",
    "dataset_test_for_espagne = import_dataset(TEST_ESPAGNE_FOLDER, class_espagne_expected_outputs)\n",
    "dataset_train_for_espagne = import_dataset(TRAIN_ESPAGNE_FOLDER, class_espagne_expected_outputs)\n",
    "\n",
    "class_france_expected_outputs = [0, 1, 0]\n",
    "dataset_test_for_france = import_dataset(TEST_FRANCE_FOLDER, class_france_expected_outputs)\n",
    "dataset_train_for_france = import_dataset(TRAIN_FRANCE_FOLDER, class_france_expected_outputs)\n",
    "\n",
    "class_japon_expected_outputs = [0, 0, 1]\n",
    "dataset_test_for_japon = import_dataset(TEST_JAPON_FOLDER, class_japon_expected_outputs)\n",
    "dataset_train_for_japon = import_dataset(TRAIN_JAPON_FOLDER, class_japon_expected_outputs)\n",
    "\n",
    "final_dataset_test = dataset_test_for_espagne + dataset_test_for_france + dataset_test_for_japon\n",
    "final_dataset_train = dataset_train_for_espagne + dataset_train_for_france + dataset_train_for_japon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in final_dataset_test:\n",
    "\n",
    "    the_image = value[\"value\"].tolist()\n",
    "    the_classe = value[\"classe\"]\n",
    "\n",
    "    x_test.append(the_image)\n",
    "    y_test.append(the_classe)\n",
    "\n",
    "for value in final_dataset_train:\n",
    "\n",
    "    the_image = value[\"value\"].tolist()\n",
    "    the_classe = value[\"classe\"]\n",
    "\n",
    "    x_train.append(the_image)\n",
    "    y_train.append(the_classe)\n",
    "\n",
    "dataset_inputs = x_train\n",
    "dataset_outputs = y_train\n",
    "\n",
    "initiate_dataset_inputs_size = len(dataset_inputs[0])\n",
    "initiate_dataset_inputs_type = ctypes.c_float * initiate_dataset_inputs_size\n",
    "\n",
    "classes_initiate_dataset_inputs_size = initiate_dataset_inputs_size * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_result = []\n",
    "\n",
    "for sublist in dataset_inputs:\n",
    "    for item in sublist:\n",
    "        inputs_result.append(item)\n",
    "\n",
    "dataset_inputs = inputs_result\n",
    "\n",
    "outputs_result = []\n",
    "\n",
    "for sublist in dataset_outputs:\n",
    "    for item in sublist:\n",
    "        outputs_result.append(item)\n",
    "\n",
    "dataset_outputs = outputs_result\n",
    "\n",
    "arr = [initiate_dataset_inputs_size, classes_initiate_dataset_inputs_size, 3]\n",
    "arr_size = len(arr)\n",
    "arr_type = ctypes.c_int * arr_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train/test to array\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ------------------------------------------- ####\n",
    "#### ------------LOAD MODELS---------------------#### \n",
    "#### ------------------------------------------- ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_pmc_a = tf.keras.models.load_model(\"../models/keras_models/model_a.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pmc_b = tf.keras.models.load_model(\"../models/keras_models/model_b.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pmc_c = tf.keras.models.load_model(\"../models/keras_models/model_c.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pmc_d = tf.keras.models.load_model(\"../models/keras_models/model_d.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ------------------------------------------- ####\n",
    "#### ------ DEFINE THE TRAINING ALGORITHM ------ #### \n",
    "#### ------------------------------------------- ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZER = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "LOSS = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "METRICS = [\n",
    "    tf.keras.metrics.CategoricalAccuracy(name='acc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_pmc_a.compile(\n",
    "    optimizer=OPTIMIZER,\n",
    "    loss=LOSS,\n",
    "    metrics=METRICS\n",
    ")\n",
    "\n",
    "model_pmc_b.compile(\n",
    "    optimizer=OPTIMIZER,\n",
    "    loss=LOSS,\n",
    "    metrics=METRICS\n",
    ")\n",
    "\n",
    "model_pmc_c.compile(\n",
    "    optimizer=OPTIMIZER,\n",
    "    loss=LOSS,\n",
    "    metrics=METRICS\n",
    ")\n",
    "\n",
    "model_pmc_d.compile(\n",
    "    optimizer=OPTIMIZER,\n",
    "    loss=LOSS,\n",
    "    metrics=METRICS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ------------------------------------------- ####\n",
    "#### ------------- TRAIN MODEL (A) ------------- #### \n",
    "#### ------------------------------------------- ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks for saving the checkpoints at every epoch.\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint('../models/keras_models/model_a.h5', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WAQThq539CEJ"
   },
   "outputs": [],
   "source": [
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"../models/keras_models/keras_logs/\" + datetime.datetime.now().strftime(\"model_a_%Y%m%d-%H%M%S\"), \n",
    "    histogram_freq=1\n",
    ")\n",
    "\n",
    "history_a = model_pmc_a.fit(\n",
    "    x=x_train, \n",
    "    y=y_train, \n",
    "    epochs=1000, \n",
    "    validation_data=(x_test, y_test), \n",
    "    callbacks=[\n",
    "        tensorboard_cb,\n",
    "        checkpoint_cb,\n",
    "        \n",
    "        \n",
    "    ]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_a.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ------------------------------------------- ####\n",
    "#### ------------- TRAIN MODEL (B) ------------- #### \n",
    "#### ------------------------------------------- ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks for saving the checkpoints at every epoch.\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint('../models/keras_models/model_b.h5', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"../models/keras_models/keras_logs/\" + datetime.datetime.now().strftime(\"model_b_%Y%m%d-%H%M%S\"), \n",
    "    histogram_freq=1\n",
    ")\n",
    "\n",
    "history_b = model_pmc_b.fit(\n",
    "    x=x_train, \n",
    "    y=y_train, \n",
    "    epochs=1000, \n",
    "    validation_data=(x_test, y_test), \n",
    "    callbacks=[\n",
    "        tensorboard_cb,\n",
    "        checkpoint_cb,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_b.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ------------------------------------------- ####\n",
    "#### ------------- TRAIN MODEL (C) ------------- #### \n",
    "#### ------------------------------------------- ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks for saving the checkpoints at every epoch.\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint('../models/keras_models/model_c.h5', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"../models/keras_models/keras_logs/\" + datetime.datetime.now().strftime(\"model_c_%Y%m%d-%H%M%S\"), \n",
    "    histogram_freq=1\n",
    ")\n",
    "\n",
    "history_c = model_pmc_c.fit(\n",
    "    x=x_train, \n",
    "    y=y_train, \n",
    "    epochs=1000, \n",
    "    validation_data=(x_test, y_test), \n",
    "    callbacks=[\n",
    "        tensorboard_cb,\n",
    "        checkpoint_cb,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history_c.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ------------------------------------------- ####\n",
    "#### ------------- TRAIN MODEL (D) ------------- #### \n",
    "#### ------------------------------------------- ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks for saving the checkpoints at every epoch.\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint('../models/keras_models/model_d.h5', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"../models/keras_models/keras_logs/\" + datetime.datetime.now().strftime(\"model_d_%Y%m%d-%H%M%S\"), \n",
    "    histogram_freq=1\n",
    ")\n",
    "\n",
    "history_d = model_pmc_d.fit(\n",
    "    x=x_train, \n",
    "    y=y_train, \n",
    "    epochs=1000, \n",
    "    validation_data=(x_test, y_test), \n",
    "    callbacks=[\n",
    "        tensorboard_cb,\n",
    "        checkpoint_cb,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_d.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "get_started.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
